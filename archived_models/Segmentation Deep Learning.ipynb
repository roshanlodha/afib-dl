{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2845176f",
   "metadata": {},
   "source": [
    "# Detection of AF Recurrence Using Deep Learning Approaches of Segmented Pulmonary Vein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f729e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "import re\n",
    "\n",
    "from scipy.ndimage import zoom\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_curve, auc\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Lambda\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from nilearn import plotting\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.image\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c6d4bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# define directory\n",
    "input_folder = './data/vanderbilt/' # use ./data/small_batch_test/' for testing\n",
    "\n",
    "# load demographics data\n",
    "dem = pd.read_csv(\"./data/vanderbilt_ct_phenotype_2-14-23.csv\") # use pd.read_excel(\"./CCF_CT_demographic.xlsx\") for CCF\n",
    "\n",
    "if not os.path.exists(\"./data/projections\"): os.makedirs(\"./data/projections\")\n",
    "if not os.path.exists(\"./slices\"): os.makedirs(\"./slices\")\n",
    "if not os.path.exists(\"./plots\"): os.makedirs(\"./plots\")\n",
    "\n",
    "# define desired output voxel size\n",
    "output_spacing = (1.0, 1.0, 1.0)  # 1 mm isotropic spacing\n",
    "\n",
    "# define number of clusters to create\n",
    "n_clusters = 2\n",
    "\n",
    "# load all NIfTI files in input folder\n",
    "resampled_data = []\n",
    "projected_data = []\n",
    "scan_IDs = []\n",
    "\n",
    "dem.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ce3837",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading and resampling NIfTI files...\")\n",
    "for file_name in tqdm(os.listdir(input_folder), desc='Progress', unit='image'):\n",
    "    if file_name.endswith('.nii.gz'):\n",
    "        if not int(re.search(r\"Cardiac_(\\d+)_\", file_name).group(1)) in dem['study_id'].unique():\n",
    "            pass\n",
    "        file_path = os.path.join(input_folder, file_name)\n",
    "        img = nib.load(file_path)\n",
    "        scan_IDs.append(re.search(r\"Cardiac_(\\d+)_\", file_name).group(1))\n",
    "\n",
    "        # resample the loaded image\n",
    "        input_spacing = img.header.get_zooms()\n",
    "        resampling_factors = tuple(np.array(input_spacing) / np.array(output_spacing))\n",
    "        resampled_image = zoom(img.get_fdata(), resampling_factors, order=1)\n",
    "\n",
    "        # pad the images to equal size\n",
    "        target_shape = (500, 500, 500)\n",
    "        x_pad = max(target_shape[0] - resampled_image.shape[0], 0)\n",
    "        y_pad = max(target_shape[1] - resampled_image.shape[1], 0)\n",
    "        z_pad = max(target_shape[2] - resampled_image.shape[2], 0)\n",
    "        x_pad_before = x_pad // 2\n",
    "        x_pad_after = x_pad - x_pad_before\n",
    "        y_pad_before = y_pad // 2\n",
    "        y_pad_after = y_pad - y_pad_before\n",
    "        z_pad_before = z_pad // 2\n",
    "        z_pad_after = z_pad - z_pad_before\n",
    "        resampled_image_padded = np.pad(resampled_image, ((x_pad_before, x_pad_after), (y_pad_before, y_pad_after), (z_pad_before, z_pad_after)), mode='constant', constant_values=0)\n",
    "\n",
    "        resampled_data.append(resampled_image_padded)\n",
    "\n",
    "        # create a 2D projection of the 3D images\n",
    "        proj = np.sum(resampled_image_padded, axis = 2)\n",
    "        proj_path = \"./data/projections/\" + file_name[:-7] + \".png\"\n",
    "        matplotlib.image.imsave(proj_path, proj)\n",
    "\n",
    "        projected_data.append(proj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12596b28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# extract the image_id and af_recur columns and store in a new dataframe\n",
    "af_recur_status = dem[['study_id', 'recurrence']].astype({\"study_id\": \"string\"})\n",
    "\n",
    "# filter the dataframe to only include rows where image_id is in the scan_id vector\n",
    "af_recur_status = af_recur_status[af_recur_status['study_id'].isin(scan_IDs)]\n",
    "\n",
    "# sort the dataframe based on the order of the scan_id vector\n",
    "af_recur_status = af_recur_status.set_index('study_id').loc[scan_IDs].reset_index()\n",
    "\n",
    "af_recur_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7d48c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store af_recur_status\n",
    "%store projected_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb400a32",
   "metadata": {},
   "source": [
    "## Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924c76a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r af_recur_status\n",
    "%store -r projected_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b95caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "af_recur = np.array(af_recur_status['recurrence'].values).reshape(-1, 1)\n",
    "preprocessed_images = np.array(projected_data).reshape(-1, 500, 500, 1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(projected_data, af_recur, test_size=0.1, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)\n",
    "\n",
    "X_train = np.array(X_train).reshape(-1, 500, 500, 1)\n",
    "X_val = np.array(X_val).reshape(-1, 500, 500, 1)\n",
    "X_test = np.array(X_test).reshape(-1, 500, 500, 1)\n",
    "y_train = np.array(y_train).reshape(-1, 1)\n",
    "y_val = np.array(y_val).reshape(-1, 1)\n",
    "y_test = np.array(y_test).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e24f8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained VGG16 model\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(500, 500, 3))\n",
    "\n",
    "# Freeze the pre-trained layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Create a new model\n",
    "model = Sequential()\n",
    "model.add(Lambda(lambda x: tf.image.grayscale_to_rgb(x)))  # Convert grayscale to RGB\n",
    "model.add(base_model)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=5, batch_size=16)\n",
    "\n",
    "%store model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c86c955",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f740e3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Predicting probabilities for the positive class in the testing set\n",
    "y_test_prob = model.predict(X_test)\n",
    "\n",
    "# Calculating false positive rate, true positive rate, and threshold for ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_test_prob)\n",
    "\n",
    "# Calculating the area under the ROC curve (AUC)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plotting the ROC curve\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (AUC = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a8be5d",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70edd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten each image\n",
    "flattened_images = np.array([np.array(img.flatten()) for img in projected_data])\n",
    "\n",
    "# Perform PCA\n",
    "pca = PCA(n_components = min(len(flattened_images), flattened_images[0].size)) # could use just 2 PCs\n",
    "pca.fit(flattened_images)\n",
    "reduced_images = pca.transform(flattened_images)\n",
    "\n",
    "# Create a scatter plot using seaborn\n",
    "pca_df = pd.DataFrame({'PC1':reduced_images[:, 0], 'PC2':reduced_images[:, 1], 'Recurrence':af_recur})\n",
    "pc_plot = sns.scatterplot(data=pca_df, x=\"PC1\", y=\"PC2\", hue=\"Recurrence\")\n",
    "pc_plot.set_title(\"PCA of 2D Projections\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d6fa11",
   "metadata": {},
   "source": [
    "## K-Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da07f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform k-means clustering\n",
    "print(\"Performing K-means clustering on projections...\")\n",
    "kmeans = KMeans(n_clusters=2)  # Choose the number of clusters you want to form\n",
    "kmeans.fit(reduced_images)\n",
    "labels = kmeans.labels_\n",
    "\n",
    "# Print the labels for each image\n",
    "for i, label in enumerate(labels):\n",
    "    print(f\"Image {i+1} belongs to cluster {label+1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1006d4ec",
   "metadata": {},
   "source": [
    "## DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb758c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the DBSCAN clustering algorithm\n",
    "dbscan = DBSCAN(eps=0.5, min_samples=5)\n",
    "\n",
    "# fit the algorithm to the flattened image data\n",
    "clusters = dbscan.fit_predict(flattened_images)\n",
    "\n",
    "# print the number of clusters and their indices\n",
    "n_clusters = len(set(clusters)) - (1 if -1 in clusters else 0)\n",
    "print(\"Number of clusters:\", n_clusters)\n",
    "print(\"Cluster indices:\", clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2638cf5",
   "metadata": {},
   "source": [
    "## CNN-DL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203f93db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.array(projected_data), af_recur, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], 500, 500, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 500, 500, 1)\n",
    "\n",
    "# Define the model architecture\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (5, 5), activation='relu', input_shape=X_train.shape[1:]))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (5, 5), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=2, batch_size=8, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64716e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training and validation accuracy over time\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a7c06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate the false positive rate and true positive rate for different thresholds\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "\n",
    "# Calculate the area under the ROC curve\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot the ROC curve\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

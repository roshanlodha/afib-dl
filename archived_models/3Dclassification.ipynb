{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8228ee96",
   "metadata": {},
   "source": [
    "# 3D image classification from CT scans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f051897d",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0eb0f691",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-27 12:15:27.095138: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27034f6",
   "metadata": {},
   "source": [
    "## Loading in the Vanderbilt and CCF scans\n",
    "WLOG, the first 200 are chosen as a training set, and the last 51 are chosen as a validation set. Importantly, the dataset sizes are made equal by trunacting the Vanderbilt set to match the size of the CCF set. This is done to prevent a biased model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f66c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vandy_scan_paths = [\n",
    "    os.path.join(os.getcwd(), \"data\", \"vanderbilt\", x)\n",
    "    for x in os.listdir(os.path.join(os.getcwd(), \"data\", \"vanderbilt\"))\n",
    "]\n",
    "\n",
    "ccf_scan_paths = [\n",
    "    os.path.join(os.getcwd(), \"data\", \"ccf/pulm\", x)\n",
    "    for x in os.listdir(os.path.join(os.getcwd(), \"data\", \"ccf/pulm\"))\n",
    "]\n",
    "\n",
    "print(\"CT scans from Vanderbilt: \" + str(len(vandy_scan_paths)))\n",
    "print(\"CT scans from CCF: \" + str(len(ccf_scan_paths)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36169025",
   "metadata": {},
   "source": [
    "## Preprocessing Samples\n",
    "CT scans are read in the Nifti format (extension .nii) using the `nibabel` package. CT scans store raw voxel intensity in Hounsfield units (HU) which range from -1024 to above 2000 in this dataset. Regions with an intensity above 400 are bones, so a threshold between -1000 and 400 is commonly used to normalize CT scans.\n",
    "\n",
    "To process the data, we do the following:\n",
    "\n",
    "We first rotate the volumes by 90 degrees, so the orientation is fixed\n",
    "We scale the HU values to be between 0 and 1.\n",
    "We resize width, height and depth.\n",
    "\n",
    "Here we define several helper functions to process the data. These functions will be used when building training and validation datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d1e662d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "\n",
    "from scipy import ndimage\n",
    "\n",
    "\n",
    "def read_nifti_file(filepath):\n",
    "    \"\"\"Read and load volume\"\"\"\n",
    "    # Read file\n",
    "    scan = nib.load(filepath)\n",
    "    # Get raw data\n",
    "    scan = scan.get_fdata()\n",
    "    return scan\n",
    "\n",
    "\n",
    "def normalize(volume):\n",
    "    \"\"\"Normalize the volume\"\"\"\n",
    "    min = -1000\n",
    "    max = 400\n",
    "    volume[volume < min] = min\n",
    "    volume[volume > max] = max\n",
    "    volume = (volume - min) / (max - min)\n",
    "    volume = volume.astype(\"float32\")\n",
    "    return volume\n",
    "\n",
    "\n",
    "def resize_volume(img):\n",
    "    \"\"\"Resize across z-axis\"\"\"\n",
    "    # Set the desired depth\n",
    "    desired_depth = 64\n",
    "    desired_width = 128\n",
    "    desired_height = 128\n",
    "    # Get current depth\n",
    "    current_depth = img.shape[-1]\n",
    "    current_width = img.shape[0]\n",
    "    current_height = img.shape[1]\n",
    "    # Compute depth factor\n",
    "    depth = current_depth / desired_depth\n",
    "    width = current_width / desired_width\n",
    "    height = current_height / desired_height\n",
    "    depth_factor = 1 / depth\n",
    "    width_factor = 1 / width\n",
    "    height_factor = 1 / height\n",
    "    # Rotate\n",
    "    img = ndimage.rotate(img, 90, reshape=False)\n",
    "    # Resize across z-axis\n",
    "    img = ndimage.zoom(img, (width_factor, height_factor, depth_factor), order=1)\n",
    "    return img\n",
    "\n",
    "\n",
    "def process_scan(path):\n",
    "    \"\"\"Read and resize volume\"\"\"\n",
    "    # Read scan\n",
    "    volume = read_nifti_file(path)\n",
    "    # Normalize\n",
    "    volume = normalize(volume)\n",
    "    # Resize width, height and depth\n",
    "    volume = resize_volume(volume)\n",
    "    print(\"processed \" + path)\n",
    "    return volume"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892ce80b",
   "metadata": {},
   "source": [
    "## Building train and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1a7d74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ccf_image_ids = [f.removesuffix(\".nii.gz\") for f in os.listdir(os.path.join(os.getcwd(), \"data\", \"ccf/pulm\"))]\n",
    "\n",
    "ccf_labels_df = pd.read_excel(\"./data/CCF_CT_demographic.xlsx\") # read\n",
    "\n",
    "# filter demographic table based on available scans\n",
    "ccf_labels_df['image_id'] = ccf_labels_df['image_id'].astype(str)\n",
    "ccf_labels_df = ccf_labels_df[ccf_labels_df['image_id'].isin(ccf_image_ids)]\n",
    "\n",
    "# sort the demographics table based on the scan order\n",
    "ccf_labels_df['image_id'] = ccf_labels_df['image_id'].astype(\"category\")\n",
    "ccf_labels_df['image_id'] = ccf_labels_df['image_id'].cat.set_categories(ccf_image_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f570254d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ccf_labels = ccf_labels_df['af_recur']\n",
    "\n",
    "mask = np.array(ccf_labels_df['af_recur'].isna())\n",
    "ccf_labels = np.ma.masked_array(ccf_labels, mask).compressed().astype(int)\n",
    "\n",
    "ccf_scan_paths = [\n",
    "    os.path.join(os.getcwd(), \"data\", \"ccf/pulm\", x)\n",
    "    for x in os.listdir(os.path.join(os.getcwd(), \"data\", \"ccf/pulm\"))\n",
    "]\n",
    "ccf_scan_paths = np.ma.masked_array(ccf_scan_paths, mask).compressed()\n",
    "\n",
    "n_train = int(len(ccf_labels)*0.8) if len(ccf_labels) == len(ccf_scan_paths) else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a928ab18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed /Users/lodhar/Projects/afib.dl/data/ccf/pulm/700006139.nii.gz\n"
     ]
    }
   ],
   "source": [
    "# Read and process the scans.\n",
    "# Each scan is resized across height, width, and depth and rescaled.\n",
    "ccf_scans = np.array([process_scan(path) for path in ccf_scan_paths])\n",
    "\n",
    "# Split data in the ratio 80-20 for training and validation.\n",
    "x_train = ccf_scans[:n_train]\n",
    "y_train = ccf_labels[:n_train]\n",
    "x_val = ccf_scans[n_train:]\n",
    "y_val = ccf_labels[n_train:]\n",
    "print(\n",
    "    \"Number of samples in train and validation are %d and %d.\"\n",
    "    % (x_train.shape[0], x_val.shape[0])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f4a272",
   "metadata": {},
   "source": [
    "## Data Augmentation\n",
    "\n",
    "Data augmentation is done here by rotating the CT scans at random angles during training. This is used to artificially expand the data-set. This is helpful when we are given a data-set with very few data samples as in our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42124390",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "from scipy import ndimage\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def rotate(volume):\n",
    "    \"\"\"Rotate the volume by a few degrees\"\"\"\n",
    "\n",
    "    def scipy_rotate(volume):\n",
    "        # define some rotation angles\n",
    "        angles = [-20, -10, -5, 5, 10, 20]\n",
    "        # pick angles at random\n",
    "        angle = random.choice(angles)\n",
    "        # rotate volume\n",
    "        volume = ndimage.rotate(volume, angle, reshape=False)\n",
    "        volume[volume < 0] = 0\n",
    "        volume[volume > 1] = 1\n",
    "        return volume\n",
    "\n",
    "    augmented_volume = tf.numpy_function(scipy_rotate, [volume], tf.float32)\n",
    "    return augmented_volume\n",
    "\n",
    "\n",
    "def train_preprocessing(volume, label):\n",
    "    \"\"\"Process training data by rotating and adding a channel.\"\"\"\n",
    "    # Rotate volume\n",
    "    volume = rotate(volume)\n",
    "    volume = tf.expand_dims(volume, axis=3)\n",
    "    return volume, label\n",
    "\n",
    "\n",
    "def validation_preprocessing(volume, label):\n",
    "    \"\"\"Process validation data by only adding a channel.\"\"\"\n",
    "    volume = tf.expand_dims(volume, axis=3)\n",
    "    return volume, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe1da3b",
   "metadata": {},
   "source": [
    "While defining the train and validation data loader, the training data is passed through and augmentation function which randomly rotates volume at different angles. Note that the validation data is not rotated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec18f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data loaders.\n",
    "train_loader = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "validation_loader = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "\n",
    "batch_size = 2\n",
    "# Augment the on the fly during training.\n",
    "train_dataset = (\n",
    "    train_loader.shuffle(len(x_train))\n",
    "    .map(train_preprocessing)\n",
    "    .batch(batch_size)\n",
    "    .prefetch(2)\n",
    ")\n",
    "# Only rescale.\n",
    "validation_dataset = (\n",
    "    validation_loader.shuffle(len(x_val))\n",
    "    .map(validation_preprocessing)\n",
    "    .batch(batch_size)\n",
    "    .prefetch(2)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52101f52",
   "metadata": {},
   "source": [
    "### Visualizing CT scans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8c6e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = train_dataset.take(1)\n",
    "images, labels = list(data)[0]\n",
    "images = images.numpy()\n",
    "image = images[0]\n",
    "print(\"Dimension of the CT scan is:\", image.shape)\n",
    "plt.imshow(np.squeeze(image[:, :, 30]), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb50281",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_slices(num_rows, num_columns, width, height, data):\n",
    "    \"\"\"Plot a montage of 20 CT slices\"\"\"\n",
    "    data = np.rot90(np.array(data))\n",
    "    data = np.transpose(data)\n",
    "    data = np.reshape(data, (num_rows, num_columns, width, height))\n",
    "    rows_data, columns_data = data.shape[0], data.shape[1]\n",
    "    heights = [slc[0].shape[0] for slc in data]\n",
    "    widths = [slc.shape[1] for slc in data[0]]\n",
    "    fig_width = 12.0\n",
    "    fig_height = fig_width * sum(heights) / sum(widths)\n",
    "    f, axarr = plt.subplots(\n",
    "        rows_data,\n",
    "        columns_data,\n",
    "        figsize=(fig_width, fig_height),\n",
    "        gridspec_kw={\"height_ratios\": heights},\n",
    "    )\n",
    "    for i in range(rows_data):\n",
    "        for j in range(columns_data):\n",
    "            axarr[i, j].imshow(data[i][j], cmap=\"gray\")\n",
    "            axarr[i, j].axis(\"off\")\n",
    "    plt.subplots_adjust(wspace=0, hspace=0, left=0, right=1, bottom=0, top=1)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Visualize montage of slices.\n",
    "# 4 rows and 10 columns for 100 slices of the CT scan.\n",
    "plot_slices(4, 10, 128, 128, image[:, :, :40])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63397606",
   "metadata": {},
   "source": [
    "## Define a 3D convolutional neural network\n",
    "The architecture of the 3D CNN used in this example\n",
    "is based on [this paper](https://arxiv.org/abs/2007.13224)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa726bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(width=128, height=128, depth=64):\n",
    "    \"\"\"Build a 3D convolutional neural network model.\"\"\"\n",
    "\n",
    "    inputs = keras.Input((width, height, depth, 1))\n",
    "\n",
    "    x = layers.Conv3D(filters=64, kernel_size=3, activation=\"relu\")(inputs)\n",
    "    x = layers.MaxPool3D(pool_size=2)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.Conv3D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPool3D(pool_size=2)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.Conv3D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPool3D(pool_size=2)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.Conv3D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
    "    x = layers.MaxPool3D(pool_size=2)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.GlobalAveragePooling3D()(x)\n",
    "    x = layers.Dense(units=512, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "\n",
    "    outputs = layers.Dense(units=1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    # Define the model.\n",
    "    model = keras.Model(inputs, outputs, name=\"3dcnn\")\n",
    "    return model\n",
    "\n",
    "\n",
    "# Build model.\n",
    "model = get_model(width=128, height=128, depth=64)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8a67df",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45141352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model.\n",
    "initial_learning_rate = 0.0001\n",
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate, decay_steps=100000, decay_rate=0.96, staircase=True\n",
    ")\n",
    "model.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=lr_schedule),\n",
    "    metrics=[\"acc\"],\n",
    ")\n",
    "\n",
    "# Define callbacks.\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\n",
    "    \"3d_image_classification.h5\", save_best_only=True\n",
    ")\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(monitor=\"val_acc\", patience=15)\n",
    "\n",
    "# Train the model, doing validation at the end of each epoch\n",
    "epochs = 100\n",
    "model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=validation_dataset,\n",
    "    epochs=epochs,\n",
    "    shuffle=True,\n",
    "    verbose=2,\n",
    "    callbacks=[checkpoint_cb, early_stopping_cb],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519681d3",
   "metadata": {},
   "source": [
    "## Visualizing model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0938507",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(20, 3))\n",
    "ax = ax.ravel()\n",
    "\n",
    "for i, metric in enumerate([\"acc\", \"loss\"]):\n",
    "    ax[i].plot(model.history.history[metric])\n",
    "    ax[i].plot(model.history.history[\"val_\" + metric])\n",
    "    ax[i].set_title(\"Model {}\".format(metric))\n",
    "    ax[i].set_xlabel(\"epochs\")\n",
    "    ax[i].set_ylabel(metric)\n",
    "    ax[i].legend([\"train\", \"val\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6288f16a",
   "metadata": {},
   "source": [
    "## Made predictions on a single CT scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3951fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"3d_image_classification.h5\")\n",
    "prediction = model.predict(np.expand_dims(x_val[0], axis=0))[0]\n",
    "scores = [1 - prediction[0], prediction[0]]\n",
    "\n",
    "class_names = [\"normal\", \"abnormal\"]\n",
    "for score, name in zip(scores, class_names):\n",
    "    print(\n",
    "        \"This model is %.2f percent confident that CT scan is %s\"\n",
    "        % ((100 * score), name)\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
